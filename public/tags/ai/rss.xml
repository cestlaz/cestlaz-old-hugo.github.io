<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on C&#39;est la Z</title>
    <link>https://cestlaz.github.io/tags/ai/</link>
    <description>C&#39;est la Z (ai)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 14:37:10 -0400</lastBuildDate>
    
    <atom:link href="https://cestlaz.github.io/tags/ai/rss.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>AI without guardrails</title>
      <link>https://cestlaz.github.io/post/ai-without-guardrails/</link>
      <pubDate>Fri, 26 Jul 2024 14:37:10 -0400</pubDate>
      
      <guid>https://cestlaz.github.io/post/ai-without-guardrails/</guid>
      <description>&lt;p&gt;
CSTA was only a week ago but I&amp;#39;ve already been trotting out things
learned there in conversations. Specifically, during the panel
keynote, one panelist, while discussing the affects of AI cited a
study.&lt;/p&gt;
&lt;p&gt;
Two groups of programmers were tasked with writing some safe and
secure code. One group used AI tools like copilot and chatGPT. The
other didn&amp;#39;t&lt;/p&gt;
&lt;p&gt;
When all was said and done, the group that &lt;strong&gt;didn&amp;#39;t&lt;/strong&gt; use the AI tools
produced more secure code. The group that did use the AI tools not
only produced worse code but they were actually more confident in
their code.&lt;/p&gt;
&lt;p&gt;
To be honest, this really didn&amp;#39;t come as a surprise.&lt;/p&gt;
&lt;p&gt;
Today I was thinking about this again. My friend Bethany Crystal wrote
up a &lt;a href=&#34;https://paragraph.xyz/@bethanycrystal/beyond-the-classroom-leveraging-ai-for-educational-innovation&#34;&gt;post&lt;/a&gt; on leveraging AI. Lots of good stuff in the post, one point
was when Bethany talks of when she was with StackOverflow and how it
became such an important part of developers workflows and how AI is
now becoming the same but beyond coding.&lt;/p&gt;
&lt;p&gt;
The post is a great post to get people thinking about using AI in
their workflows but we also have to be reminded that AI without
verification can be dangerous.&lt;/p&gt;
&lt;p&gt;
Bethany gives an example of using chatGPT in a similar vein to
StackOverflow - as a timesaver to generate content from which she
would then build her actual work.&lt;/p&gt;
&lt;p&gt;
To do this, she asks chatGPT:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi, I&amp;#39;m a principal at a public high school in the South Bronx. Can
you help me make a case about the importance of project-based learning
to teachers who are skeptical about why we need to teach kids how to
code?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
If one is an educator and already knows their stuff on Project Based
Learning (PBL), the results are a nice start if you&amp;#39;re building a
presentation, going to address your faculty, or a number of other
tasks.&lt;/p&gt;
&lt;p&gt;
On the other hand, if you&amp;#39;re someone who just got out of Teach for
America and are now making the next greatest education startup but
don&amp;#39;t really know the real deal in education, it&amp;#39;s not nearly as
helpful. I ran this query twice, the second time, the answer didn&amp;#39;t
talk at all about some of the problems with PBL - class size and time
issues, project storage over days for physical projects, prep time
needed to set up each experience and many more. The first time I ran
it, it mentioned some of the issues with PBL but just in the most
generic sense &amp;#34;make sure teachers have the support they need.&amp;#34;&lt;/p&gt;
&lt;p&gt;
Both answers also conflated coding and PBL so if the person using
chatGPT doesn&amp;#39;t have as strong education and in this case programming
background the chatGPT solution can do more harm than good.&lt;/p&gt;
&lt;p&gt;
I then, for kicks, tried this prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi, I&amp;#39;m a principal at a public high school in the South Bronx. Can
you help me make a case about the importance of the use of lectures in
teaching who are skeptical about why we need to teach kids how to
code?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
I had to change the wording a bit but it&amp;#39;s basically the same ask but
with the use of lectures instead of projects.&lt;/p&gt;
&lt;p&gt;
While parts of the response are very specific to lectures, the entire
answer actually reads very similarly to the PBL answers and its
justifications are just as strong (or weak depending on your point of
view).&lt;/p&gt;
&lt;p&gt;
All of my queries resulted in  some incorrect assertions.&lt;/p&gt;
&lt;p&gt;
Now, I&amp;#39;m not saying at all that one shouldn&amp;#39;t use these AI tools - we
should - if we already know about the domain we&amp;#39;re using them in. They
can be great at generating code for well understood algorithms - we
just have to make sure to verify what&amp;#39;s been generated. They can help
phrase a difficult paragraph or reframe an argument and assist us in
many other ways. The important thing, and the thing that that first
group of programmers from the experiment up top forgot, is that we
have to verify what these tools give us. We end up using them like a
curated library and it isn&amp;#39;t.&lt;/p&gt;
&lt;p&gt;
Tools like chatGPT look at a corpus of documents and probabilistically
generate its content. This means it&amp;#39;s basing its results on the
documents out there.&lt;/p&gt;
&lt;p&gt;
In the case of code, we know that there&amp;#39;s a lot more bad code out
there than good. This means that while chatGPT can probably easily
generate code for a really well known algorithm like a sort, we&amp;#39;ve got
to question and test anything it puts out.&lt;/p&gt;
&lt;p&gt;
Likewise for education issues, there&amp;#39;s a lot of bad material on
education out there. A lot of garbage has been published and treated
like &amp;#34;the true way&amp;#34; to teach and to run schools. Things that
&amp;#34;reformers&amp;#34; love because they cut costs but teachers know are
crap. Things that are likewise pet theories of education that have
become popular but are no better and are frequently worse than what
teachers know are tried and true methods.&lt;/p&gt;
&lt;p&gt;
What&amp;#39;s more a chatGPT response can lack nuance. I can picture someone
who&amp;#39;s starting a school - a non educator let&amp;#39;s say, heard from a
person that PBL is good. Now, I know some people who swear by PBL and
say to use it all the time - those are people in super selective
private schools with tremendous resources and ultra small classes. The
reality is that PBL is good and should be used as appropriate but
there are other good techniques that will be better under some
circumstances and worse under others. This person starting the school
then dives into the AI with queries like I made on PBL and get a very
one sided view. Now we have a problem.&lt;/p&gt;
&lt;p&gt;
I loved Bethany&amp;#39;s post and it got me thinking more of how I can
leverage AI, of course the problem for me is that I&amp;#39;m currently
between gigs so don&amp;#39;t have any work to apply it to. It also reminded
me of the dangers of using it blindly and without guardrails.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teachers want to teach AI but how will we teach the teachers?</title>
      <link>https://cestlaz.github.io/post/teach-ai-teachers/</link>
      <pubDate>Tue, 05 Mar 2024 09:58:42 -0400</pubDate>
      
      <guid>https://cestlaz.github.io/post/teach-ai-teachers/</guid>
      <description>&lt;p&gt;
Saw &lt;a href=&#34;https://www.edweek.org/technology/how-young-is-too-young-to-teach-students-about-ai-survey-reveals-differing-opinions/2024/02&#34;&gt;this&lt;/a&gt; earlier as posted on Linkedin by Pat Yongpradit of
code.org. According to the article, nine out of ten educators think
that students should be taught how AI works prior to graduating from
high school. How it works, not just how to use it. This is a good
thing. Sure, opinions vary as to when to teach it - elementary, high
school, or across the board but still, a good thing.&lt;/p&gt;
&lt;p&gt;
It did make me think though about a few things.&lt;/p&gt;
&lt;p&gt;
First, in a way this is really just saying &amp;#34;kids should learn computer
science.&amp;#34; This too is a good thing but the bad thing is that a lot of
people talking about learning about AI don&amp;#39;t get this.&lt;/p&gt;
&lt;p&gt;
AI isn&amp;#39;t some new magic mystically appearing. It&amp;#39;s algorithms applied
on data on computers with a user interface. Sounds like CS to me, more
specifically a subset of CS. Sure the data sets are HUGE and the
algorithms, more complex than the bubble sort but at a technical
level, it&amp;#39;s a next step.&lt;/p&gt;
&lt;p&gt;
AI applications can do some really impressive things but then so could
earlier computer solutions.&lt;/p&gt;
&lt;p&gt;
AI can be filled with bias but computer systems have always been
infused with our societal biases (and we have to do better).&lt;/p&gt;
&lt;p&gt;
AI can either take away jobs or enhance productivity but the same can
be said with earlier computer innovations.&lt;/p&gt;
&lt;p&gt;
So, the call to teach how AI works is a good one but there&amp;#39;s a level
of concern that people don&amp;#39;t see that in a lot of ways this isn&amp;#39;t a
revolution but a next step and as my readers know, I fell we&amp;#39;ve gotten
some serious things wrong in the roll out of teaching CS, without
acknowledging that this comes from CS begs the question, what will we
do differently, or more specifically better. &lt;/p&gt;
&lt;p&gt;
This brings me to my next thought, and this is the bigger one - if
teachers are going to teach all our students how AI works, how are we
going to teach all those teachers?&lt;/p&gt;
&lt;p&gt;
It&amp;#39;s clear, at least to me, that the professional development, short
form training model favored by so many for CSforAll efforts is far
from ideal. It sets up content providers and politicians to be able to
say &amp;#34;we&amp;#39;ve trained all our teachers in just &lt;code&gt;n&lt;/code&gt; years&amp;#34; with &lt;code&gt;n&lt;/code&gt; being
some small number but the truth is, those teachers don&amp;#39;t really know
what they&amp;#39;re teaching and are doing a disservice to their students in
the long run &lt;sup class=&#34;footnote-reference&#34;&gt;&lt;a id=&#34;footnote-reference-1&#34; href=&#34;#footnote-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. We also see Computational Thinking efforts where
elementary school teachers relabel things they already do with CT
labels - debugging for error fixing, for example. This can be a
stepping stone to true CT and CS concepts but I&amp;#39;ve seen
implementations where just the labeling is considered good
enough. Worse, at times the teachers delivering these CT enhanced
lessons aren&amp;#39;t using the CT definitions correctly.&lt;/p&gt;
&lt;p&gt;
CSforAll in New York City has been going on for nine years. Some
states are further along in bringing CS to their schools and some
started later. Still, after a decade, we have an extremely &lt;strong&gt;long&lt;/strong&gt; way to
go. The number of high school teachers that have a deep knowledge of
CS and how to teach it still pales in comparison to other subject
areas and while elementary school teachers don&amp;#39;t require the same
depth of knowledge, they, in my opinion, as a group are also far
behind where they should be when CS is a subject equal to all the
others.&lt;/p&gt;
&lt;p&gt;
I&amp;#39;m not blaming anyone for this (other than what I already said about
the acceptance and in fact enthusiasm of the short term PD model) but
rather noting that creating a new subject area from whole cloth where
those you intend to teach it never studied the subject themselves is a
multi decade process.&lt;/p&gt;
&lt;p&gt;
What&amp;#39;s worth thinking about now though, is what are we going to do
with AI? Are we going to double down on short form PD and pay lip
service to this emerging technology? Are we going to make some serious
decisions and decide that some meaty material has to be included in
per service programs?&lt;/p&gt;
&lt;p&gt;
I&amp;#39;m a skeptic. In a country where public school teaching is regularly
derided and even in New York there&amp;#39;s talk about removing the Masters
degree requirements I&amp;#39;m not hopeful. Will we, as a society, decide to
do what&amp;#39;s right for all of our students or will we pay lip service
while those who are well resources continue to get further ahead.&lt;/p&gt;
&lt;p&gt;
Time will tell.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr class=&#34;footnotes-separatator&#34;&gt;
&lt;div class=&#34;footnote-definitions&#34;&gt;
&lt;div class=&#34;footnote-definition&#34;&gt;
&lt;sup id=&#34;footnote-1&#34;&gt;&lt;a href=&#34;#footnote-reference-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
&lt;div class=&#34;footnote-body&#34;&gt;
&lt;p&gt;PD as a first step is often necessary and can be a good start
but without meaningful long form preparation as a follow up it&amp;#39;s pure style over substance] &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Teaching with chatGPT - The Good, The Bad, and The Ugly</title>
      <link>https://cestlaz.github.io/post/chatgpt-good-bad-ugly/</link>
      <pubDate>Sun, 15 Jan 2023 11:03:52 -0400</pubDate>
      
      <guid>https://cestlaz.github.io/post/chatgpt-good-bad-ugly/</guid>
      <description>&lt;p&gt;
The plan was to talk about what we can and should do in CS classes
with respect to chatGPT type technologies but after seeing so much
discussion on how to and not to use chatGPT I thought I&amp;#39;d insert this
additional post on classroom use.&lt;/p&gt;
&lt;p&gt;
We already talked about &lt;a href=&#34;https://cestlaz.github.io/po%60st/teachgpt/&#34;&gt;the good&lt;/a&gt;. I love the idea of making an essay
with errors for proof reading and it can be a great search resource,
albeit one that needs to be error checked and I&amp;#39;m sure many other
productive teaching and teaching support applications will turn up.&lt;/p&gt;
&lt;p&gt;
We also talked about &lt;a href=&#34;https://cestlaz.github.io/post/cheatgpt/&#34;&gt;the bad&lt;/a&gt;. The big one being potential cheating -
crossing the line from research or understanding aid to using it as an
inappropriate shortcut. It also just plain out fails at times to do
what you wnat it to do but that&amp;#39;s really reasonable given what it is.&lt;/p&gt;
&lt;p&gt;
What about the ugly?&lt;/p&gt;
&lt;p&gt;
Ugly is probably the wrong word. I&amp;#39;m talking about using chatGPT or
any technology because it&amp;#39;s new and cool and not because it&amp;#39;s actually
the right tool in the right place at the right time.&lt;/p&gt;
&lt;p&gt;
This is nothing new and not restricted to education. Years ago, my
parent&amp;#39;s taxes were audited. The auditor has one of those new fangled
electronic calculators and he was so enthralled  with it that he kept
showing it off and all it could to do my parents throughout the
audit. My parents were pretty sharp overall and my dad was very good
with numbers. At the end of the day the auditor determined that my
parents didn&amp;#39;t owe taxes but actually were due a sizable refund. When
all was said and done, my dad pointed out all the times that the
auditor messed up with the calculator which resulted in the
refund. The truth was that the taxes were filed correctly to begin
with but my folks weren&amp;#39;t going to turn away free money. The auditor
should have just gone old school.&lt;/p&gt;
&lt;p&gt;
I&amp;#39;ve seen some examples already of &amp;#34;the ugly&amp;#34; and I&amp;#39;m sure there will be
more to come. Also, I want to emphasize that &amp;#34;the ugly&amp;#34; doesn&amp;#39;t
necessarily mean bad,  I just wanted to use that turn of phrase.&lt;/p&gt;
&lt;p&gt;
A friend of mine suggested using chatGPT to evaluate  essays for when
students aren&amp;#39;t comfortable with other people viewing their
work. Assuming that we&amp;#39;re confident that chatGPT will do a good job
this could work but I&amp;#39;d have some concerns. True, this could alleviate
a student&amp;#39;s fear of peer grading but building a supportive community
of peers that &lt;strong&gt;can&lt;/strong&gt; support you is important and I&amp;#39;m leery of using
technology too much as a crutch. Also that while this might offload
work from the teacher, it also removes an opportunity for the teacher
to build more of a relationship with the student through the
interaction and through their work.&lt;/p&gt;
&lt;p&gt;
I&amp;#39;m not enough of an expert on language/english classes to really
judget that bt here&amp;#39;s a similar CS related example that I saw
suggested online. Have students enter programs in into chatGPT and ask
the system to add comments. &lt;/p&gt;
&lt;p&gt;
I tried this with a couple of small intro type programs and each time
I got the same style of comments. Things like a comment on top of a
loop saying &amp;#34;loop from 1 to n&amp;#34; or on top of a line like &lt;code&gt;sum = 0&lt;/code&gt;
saying &amp;#34;initialize the sum  to 0.&amp;#34; Not good comments at all.&lt;/p&gt;
&lt;p&gt;
This, I&amp;#39;d describe as ugly. If chatGPT consistently gives these types
of comments then it&amp;#39;s pretty worthless as an activity if the goal is
to help students understand commenting and writing good code. On the
other hand, if chatGPT sometimes gives these ridiculous comments and
at other times gives good comments, well, that&amp;#39;s pretty bad as well.&lt;/p&gt;
&lt;p&gt;
Now, if it always gives bad answers it could be a fun activity. Solve
the problem in class, have chatGPT comment it, and then you can
discuss good and bad coding styles and the limits of programs like
chatGPT.&lt;/p&gt;
&lt;p&gt;
Generating lessons plans also counts to me as ugly, unless you use it
to add standards to your plans to fulfill requirements from
above. Yeah, it&amp;#39;s cool that this program can make a bare bones bullet
point lesson but you then have to read it, evaluate it, check it for
errors and then still add all the meat to the bones and customize it
for your students. I&amp;#39;d argue that if a teacher knows their stuff it&amp;#39;ll
slow them down.&lt;/p&gt;
&lt;p&gt;
Normally, when using a new technology an educator should ask
themselves if it saves time and/or effort and does it improve
instruction/learning and make sure that there&amp;#39;s some real benefit to
the use. It&amp;#39;s fine if that benefit comes later and requires some dues
to be paid now but if it&amp;#39;s just a cool new technology, the new shiny
if you would, I&amp;#39;ll pass.&lt;/p&gt;
&lt;p&gt;
As a final note, even when the ugly doesn&amp;#39;t save time or improve
instruction it&amp;#39;s not necessarily bad. A good teacher knows when a
class needs a break and also when they themselves need one. It&amp;#39;s fine
to burn some time on a fun but not productive activity either for
mental health, community building or other positive reasons. It&amp;#39;s not
healthy to be 100% on task 100% of the time and a good teacher gets
this. What&amp;#39;s important to also understand is when a new technology or
tool can be used productively and when it&amp;#39;s just a diversion.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AI For All</title>
      <link>https://cestlaz.github.io/post/pd-ai-for-all/</link>
      <pubDate>Fri, 31 Jan 2020 07:00:01 -0400</pubDate>
      
      <guid>https://cestlaz.github.io/post/pd-ai-for-all/</guid>
      <description>&lt;p&gt;
Yesterday we had another Professional Development Workshop for High
School CS Teachers and as usual, I wnat to express my thanks to
&lt;a href=&#34;digitalocean.com&#34;&gt;Digital Ocean&lt;/a&gt; for continuing to provide space, food, and great overall support.&lt;/p&gt;
&lt;p&gt;
This time though, instead of JonAlf and I having
to run the show we had a guest speaker. We were joined by &lt;a href=&#34;https://twitter.com/SarahEJudd&#34;&gt;Sarah Judd&lt;/a&gt;
of &lt;a href=&#34;http://ai-4-all.org/about/what-is-ai/&#34;&gt;AI4ALL&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;
Sarah gave an overview of what AI4ALL was up to and why but the core
of her presentation was taking us through some of the exercises 
they have been developing at AI4All. Specifically, they&amp;#39;re developing
what they call &lt;a href=&#34;http://ai-4-all.org/open-learning/&#34;&gt;AI4All Open Learning&lt;/a&gt; which consists of curricular
materials aimed at high school students. &lt;/p&gt;
&lt;p&gt;
As we only had a short time, Sarah took us on a whirlwind tour of what
they&amp;#39;re building from the baseline concepts of AI that she feels (and
I agree) that every students should know up to specific AI topics like
neural nets. Obviously you can&amp;#39;t cover even a single course in one
evening professional development session but Sarah did a great job
giving both a taste and an overview.&lt;/p&gt;
&lt;p&gt;
The activities were all engaging and and covered both ethical/societal
issues as well as the technical/CS. I appreciated that the materials weren&amp;#39;t
presented as canned experiences but rather tools that a teacher would
use to deliver their own experiences. On the other hand I&amp;#39;m skeptical
of the website&amp;#39;s claims of &amp;#34;No AI or computer science experience
necessary.&amp;#34; I&amp;#39;m a firm believer that a CS teacher must know both CS
and how to teach it - maybe not at first due to necessity, but
ultimately. Regardless, Sarah has both real teaching experience and CS
knowledge and I put more faith in what she&amp;#39;s saying than a PR blurb on a
web site. &lt;/p&gt;
&lt;p&gt;
Now you&amp;#39;ll notice I haven&amp;#39;t said anything specific about Sarah&amp;#39;s
presentation or AI4All and that&amp;#39;s because Sarah will be giving a
variation of it at SIGCSE in March. If you teach high school and are
going to be at SIGCSE, I highly recommend you check out her session.&lt;/p&gt;
&lt;p&gt;
If not, perhaps I&amp;#39;ll blog more specifics after the event.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>